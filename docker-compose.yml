version: "3.3"
#https://github.com/mvillarrealb/docker-spark-cluster/blob/master/articles/docker-compose.md
services:
  #MASTER node
  master:
    build: 
      context: .
      dockerfile: DockerFile-Spark
    image: cluster-apache-spark:3.1.2
    container_name: ${spark_master}
    ports:
      - ${spar_master_webui_port}:${spar_master_webui_port}
      - ${spark_master_port}:${spark_master_port}
      - 8081:8081
    volumes:
       - ./apps:/opt/spark-apps
       - ./data:/opt/spark-data
       - .:/home/shangupta
       - ./out/artifacts/sql_mongo_validation_jar:/home/jars
    environment:
      - SPARK_WORKLOAD=master
      - SPARK_MASTER_WEBUI_PORT=${spar_master_webui_port}
      - SPARK_MASTER_PORT=${spark_master_port}
      - SPARK_MASTER=spark://${spark_master}:${spark_master_port}
      - SPARK_LOCAL_IP=${spark_master} #hostname/ip - from .env file
      - SPARK_PUBLIC_DNS=${spark_master}  #hostname/ip - from .env file
    networks:
      - spark-network

  # WORKER Node 1
  worker-a:
    image: cluster-apache-spark:3.1.2
    container_name: ${spark_worker_1}
    ports:
      - ${spar_worker_1_webui_port}:${spar_worker_1_webui_port}
    depends_on:
      - master
    environment:
      - SPARK_MASTER=spark://${spark_master}:${spark_master_port}
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_WORKER_WEBUI_PORT=${spar_worker_1_webui_port}
      - SPARK_LOCAL_IP=${spark_worker_1} #hostname/ip - from .env file
      - SPARK_PUBLIC_DNS=${spark_worker_1} #hostname/ip - from .env file
    volumes:
       - ./apps:/opt/spark-apps
       - ./data:/opt/spark-data
       - .:/home/shangupta
       - ./out/artifacts/sql_mongo_validation_jar:/home/jars
    networks:
      - spark-network

  # WORKER Node 2
  worker-b:
    image: cluster-apache-spark:3.1.2
    container_name: ${spark_worker_2}
    ports:
      - ${spar_worker_2_webui_port}:${spar_worker_2_webui_port}
    depends_on:
      - master
    environment:
      - SPARK_MASTER=spark://${spark_master}:${spark_master_port}
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_WORKER_WEBUI_PORT=${spar_worker_2_webui_port}
      - SPARK_LOCAL_IP=${spark_worker_2} #hostname/ip - from .env file
      - SPARK_PUBLIC_DNS=${spark_worker_2} #hostname/ip - from .env file
    volumes:
        - ./apps:/opt/spark-apps
        - ./data:/opt/spark-data
        - .:/home/shangupta
        - ./out/artifacts/sql_mongo_validation_jar:/home/jars
    networks:
      - spark-network

  # demo-database:
  #   image: postgres:11.7-alpine
  #   ports: 
  #     - 5432:5432
  #   environment: 
  #     - POSTGRES_PASSWORD=casa1234

networks:
  spark-network:
    driver: bridge